{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People detection and counting with Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why count people?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting people may sound like an easy task at first thought, but it has often proven itself to be a delicate and controversial task. Take Donald Trump's inauguration in Januaray 2017 for example. President Trump and his administration were not shy to claim that \"This was the largest audience to ever witness an inauguration\". However, given the image below, would you agree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Obama_vs_Trump_Inauguration_Reuteurs_and_Pool_Camera](Obama_vs_Trump.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A view of the National Mall during Barack Obama’s first inauguration in 2009 and for Donald Trump’s inauguration in 2017\n",
    "Photos by Reuters and Pool Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "For this project, I will attempt, from a given photograph, to identify and and count the people in it using traditional computer vision techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As this is an introductory project to Computer Vision, to avoid excessive complexity, I will focus my work on photographs including only a few people and not large crouds. I will work with photographs taken from angles where the people's silouhettes are fairly clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Object Detection problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of interest in this project is the detection of a person from an image. Indeed, once we can do this, counting them is a trivial task. The detection of people is a well studied problem in the field of Image Recognition and Object Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Image Recognition and Object Detection problem is generally solved by training a binary image classifier to identify whether a patch of an image represents the considered object or not. The methodology to build such a classifier goes as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset of labelled images:\n",
    "* The images are preprocessed. \n",
    "* Significant features are extracted from these preprocessed images. \n",
    "* The extracted feature data is split into two subsets, a training set and a test set.\n",
    "* The training data is used to train a classifier model.\n",
    "* The model is evaluated and optimised using the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key step in this process is the feature extraction. To train a machine learning model effectively, the input data should describe the features that are actually significant for the considered problem. Irrelevant information, \"noise\" data, should be minimised. This is especially true in image recognition where only little information carried by an image is actually useful for detecting an object. \n",
    "\n",
    "For Imgae Recogntion and Object Detection, Haar-like features, Histogram of Oriented Gradients (HOG), Scale-Invariant Feature Transform (SIFT) and Speeded Up Robust Feature (SURF) are extensively used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a suitable feature extraction process is defined. The next issue to consider is the machine learning model. Many binary classifier model exist, it is all about finding the one that will perform best with out data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the options for feature extraction and classifying are vast, I looked into the academic litterature of the field and found three solutions for this people detection problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __The Viola-Jones object detection framework__\n",
    "\n",
    "Objects are detected here using Haar features of images and cascade classifiers that are a variant of the AdaBoost learning algorithm.\n",
    "This framework was first proposed in a paper by Paul Viola and Micheal Jones and proved to be efficient in detecting human faces.\n",
    "\n",
    "_P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. CVPR 2001, 2001_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* __Histogram of Orientend Gradients (HOG) and Support Vector Machines (SVM)__\n",
    "\n",
    "The significant features of an image are extracted and vectorised using a HOG descriptor. SVMs are then trained and used to detect objects within an image. This framework was proposed by Dalal and Triggs who published a paper, proving it's efficiency for human detection fitting this project's needs very well.\n",
    "\n",
    "_Navneet Dalal and Bill Triggs, Histograms of Oriented Gradients for Human Detection, CVPR05, 2005_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* __Deep Learning__\n",
    "\n",
    "Nowadays, deep learning algorithms are by far the best performing solutions to image recognition and object detection. Human detection using a deep learning framework should be no exception. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I want to explore traditional computer vision techniques in this project I will not go with Deep Learning right away. Although the Viola Jones framework is a reference in the field of image recognition and performs well with human faces, it is not so efficient when it comes to detecting entire people. On the other hand, using HOG and SVMs, as detailed in Dalal and Triggs paper, has a proven efficiency for human detection. I will thus go forward implementing a __HOG + SVM__ people detector in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a HOG + SVM people detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experimental part of the project, I will extensively use the [OpenCV](http://opencv.org) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting a dataset of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several relevant datasets are available online:\n",
    "    \n",
    "* [The INRIA Person Dataset](http://pascal.inrialpes.fr/data/human/) \n",
    "* [The Penn-Fudan Database for Pedestrian Detection and Segmentation](https://www.cis.upenn.edu/~jshi/ped_html/)\n",
    "* [The Caltech Pedestrian Detection Benchmark](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collected images from these sources and stored them in a Samples folder at the root directory of my project. These images are organised in two sub-folders, one for positive samples (images with people) and the other for negative samples (images with no people). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dependency modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm as sklearn_svm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import imutils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the path to the image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_image_paths = glob.glob(os.getcwd() + '/Samples/Single_Pedestrian/*')\n",
    "negative_image_paths = glob.glob(os.getcwd() + '/Samples/No_Pedestrian/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the significant features of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental idea behind the HOG descriptor is that the appearance and local form of an object in an image can be described by the distribution (\"Histogram...\") of the direction of it's edges (\"...of Oriented Gradients\").\n",
    "\n",
    "The input image is divided into given size cells. Each cell is filtered using \\[-1,0,1\\] and \\[-1,0,1\\]T kernels to obtain the intensity and orientation of the gradients. Sobel and Gaussian filters have also been tested but have not produced better results. A histogram of the orientation of the gradients is then built for each cell. The histograms are then normalised over bigger sized and overlapping blocks that group adjancent cells. This is improves the robustness to lighting changes. \n",
    "\n",
    "As a result of this process, we get a single vector describing features that are actually significant in describing the object, which is what we need to effectively train our classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DalalTriggsDiagram.png\" alt=\"Dalal_Triggs_Diagram\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure downloaded from Berkin Bilgic's \n",
    "[paper](https://goo.gl/v934WD), Fast Human Detection with Cascaded Ensembles, 2010_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and configure the HOG descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values chosen to configure my HOG descriptor are those recommended in Dalal and Triggs paper on human detection using HOG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The HOG will be computed on the entire image\n",
    "winSize = (64,128)\n",
    "#Cell and block sizes are those used in Dalal and Triggs's paper\n",
    "#A block groups 4 adjacent cells\n",
    "blockSize = (16,16)\n",
    "blockStride = (8,8)\n",
    "cellSize = (8,8)\n",
    "#The number of bins is also chosen based on Dalal and Triggs's paper\n",
    "nbins = 9\n",
    "#The following are by default values based on Dalal and Triggs's work\n",
    "derivAperture = 1\n",
    "winSigma = -1.\n",
    "histogramNormType = 0\n",
    "L2HysThreshold = 0.2\n",
    "gammaCorrection = 1\n",
    "nlevels = 64\n",
    "#Gradients are oriented\n",
    "useSignedGradients = False\n",
    "\n",
    "#Initialise the HOG descriptor\n",
    "hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, useSignedGradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the images, compute their HOG vectors and label them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compute a HOG feature vector, the input image should have 1:2 aspect ratio and be resized to 64x128. This is done in the pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_data = []\n",
    "labels = []\n",
    "\n",
    "for img in positive_image_paths:\n",
    "    #pre-processing\n",
    "    img = cv2.imread(img,0)\n",
    "    img = cv2.resize(img,(64,128))\n",
    "    \n",
    "    #computing the HOG feature vector\n",
    "    descriptor = hog.compute(img)\n",
    "    temp = []\n",
    "    for value in descriptor:\n",
    "        temp.append(value[0])\n",
    "    descriptor = temp\n",
    "    hog_data.append(descriptor)\n",
    "    #labelling\n",
    "    labels.append(1)\n",
    "\n",
    "for img in negative_image_paths:\n",
    "    #pre-processing\n",
    "    img = cv2.imread(img,0)\n",
    "    img = cv2.resize(img,(64,128))\n",
    "    #computing the HOG feature vector\n",
    "    descriptor = hog.compute(img)\n",
    "    temp = []\n",
    "    for value in descriptor:\n",
    "        temp.append(value[0])\n",
    "    descriptor = temp\n",
    "    hog_data.append(descriptor)\n",
    "    #labelling\n",
    "    labels.append(0)\n",
    "\n",
    "hog_data = np.array(hog_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all machine learning libraries include SVM modules. I will firstly train an SVM classifier from my favourite machine learning library, Scikit learn. I will secondly train OpenCV's built-in SVM classifier that relies on the LIBSVM librarwith which one can build an actual HOG detector to be applied on test images. OpenCV's classifier relies the LIBSVM library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into a test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hog_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training SciKit learn's SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SVM as SVC type with an RBF kernel\n",
    "clf = sklearn_svm.SVC(kernel='rbf')\n",
    "# Train the classifier with the training set\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating it's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or using OpenCV's built in SVM classifier to build a HOG detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SVM for OpenCV 3\n",
    "svm = cv2.ml.SVM_create()\n",
    "# Set SVM type\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "# Set SVM Kernel to Radial Basis Function (RBF) \n",
    "svm.setKernel(cv2.ml.SVM_RBF)\n",
    "\n",
    "# Train SVM on training data  \n",
    "svm.trainAuto(X_train, cv2.ml.ROW_SAMPLE, y_train)\n",
    "\n",
    "svm.save(\"svm.xml\")\n",
    "tree = ET.parse('svm.xml')\n",
    "root = tree.getroot()\n",
    "# now this is really dirty, but after ~3h of fighting OpenCV its what happens :-)\n",
    "SVs = root.getchildren()[0].getchildren()[-2].getchildren()[0] \n",
    "rho = float( root.getchildren()[0].getchildren()[-1].getchildren()[0].getchildren()[1].text )\n",
    "svmvec = [float(x) for x in re.sub( '\\s+', ' ', SVs.text ).strip().split(' ')]\n",
    "svmvec.append(-rho)\n",
    "hog.setSVMDetector( np.array(svmvec) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the HOG detector on a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select image path\n",
    "test_image_path = glob.glob(os.getcwd() + \"/Samples/test_image.bmp\")[0]\n",
    "img = cv2.imread(positive_image_paths[0],0)\n",
    "boxes, weights = hog.detectMultiScale(img)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Detection result\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best fitting bounding boxes with non-maxima suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlapThresh is fairly high allowing enough overlap to identify closely positionned people\n",
    "boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "best_fitting_boxes = non_max_suppression(boxes, probs=None, overlapThresh=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the best bounding boxes on the image\n",
    "for (xA, yA, xB, yB) in best_fitting_boxes:\n",
    "    cv2.rectangle(img, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"result\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the people detected by counting the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "People_Count = len(best_fitting_boxes)\n",
    "People_Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have thus built a functional HOG + SVM people detector that reaches this projects objectives. This detector can identify and allows me to count people appearing in a given photograph. \n",
    "\n",
    "The implementation I have presented here is fairly simple and it's performances are very limited. OpenCV actually includes a far better trained SVM model for human detection based on Dalal and Trigg's work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV's default person detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new HOG descriptor and configure the default SVM people detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select image path\n",
    "imagePath = glob.glob(os.getcwd() + '/test_image_2.bmp')[0]\n",
    "\n",
    "image = cv2.imread(imagePath,0)\n",
    "image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Detection result\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the HOG detector on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(boxes, weights) = hog.detectMultiScale(image, winStride=(4, 4), padding=(8, 8), scale=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the best fitting bounding boxes with non-maxima suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlapThresh is fairly high allowing enough overlap to identify closely positionned people\n",
    "boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "best_fitting_boxes = non_max_suppression(boxes, probs=None, overlapThresh=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the best bounding boxes on the image\n",
    "for (xA, yA, xB, yB) in best_fitting_boxes:\n",
    "    cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "    \n",
    "# Display resulting image\n",
    "cv2.imshow(\"Detection result\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the people detected by counting the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "People_Count = len(best_fitting_boxes)\n",
    "People_Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Throughout this project I have explored traditional computer vision techniques to build a functional person detector implementing a HOG + SVM classifier. This implementation enables me to effectively detect and count people in a given image, fulfilling the objectives I had set for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _P. Viola and M. Jones. Rapid object detection using a boosted cascade of simple features. CVPR 2001, 2001_\n",
    "\n",
    "* _Navneet Dalal and Bill Triggs, Histograms of Oriented Gradients for Human Detection, CVPR05, 2005_\n",
    "\n",
    "* _B. Bilgic, Fast Human Detection with Cascaded Ensembles, 2010_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ressources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _The [Learn OpenCV](https://www.learnopencv.com) website by Satya Mallick_\n",
    "* _Machine Intelligence's [object detector guide](http://www.hackevolve.com/create-your-own-object-detector/)_\n",
    "* _The [HOG person detector tutorial](http://mccormickml.com/2013/05/09/hog-person-detector-tutorial/) by Chris McCormick_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCV-master-py3",
   "language": "python",
   "name": "opencv-master-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
